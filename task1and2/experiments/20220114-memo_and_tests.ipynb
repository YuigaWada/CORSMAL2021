{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022/01/14 Memo & Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aim\n",
    "visualize model info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get & Add the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_dir: Path = pathlib.Path().cwd().resolve()\n",
    "project_root: Path = current_dir.parent\n",
    "data_dir: Path = project_root / \"data\"\n",
    "\n",
    "sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize `TaskChallenger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.size(): torch.Size([1, 8, 750, 128])\n",
      "b.size(): torch.Size([1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "TaskChallenger                                          --\n",
       "├─LogMelEncoder: 1-1                                    --\n",
       "│    └─BatchNorm2d: 2-1                                 16\n",
       "│    └─DepthWiseConv2d: 2-2                             416\n",
       "│    └─PointWiseConv2d: 2-3                             17\n",
       "│    └─TransformerEncoder: 2-4                          --\n",
       "│    │    └─CLSTokenAdder: 3-1                          129\n",
       "│    │    └─PositionalEncoding: 3-2                     --\n",
       "│    │    └─MultiheadedSelfAttention: 3-3               66,048\n",
       "│    │    └─Sequential: 3-4                             396,672\n",
       "├─T1Head: 1-2                                           --\n",
       "│    └─Linear: 2-5                                      4,128\n",
       "│    └─Linear: 2-6                                      99\n",
       "├─T2Head: 1-3                                           --\n",
       "│    └─Linear: 2-7                                      4,128\n",
       "│    └─Linear: 2-8                                      132\n",
       "================================================================================\n",
       "Total params: 471,784\n",
       "Trainable params: 471,784\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from corsmal_challenge.models.audio import LogMelEncoder  # noqa (E402)\n",
    "from corsmal_challenge.models.task1_2 import T1Head, T2Head  # noqa (E402)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batches = 1\n",
    "seq_len = 750\n",
    "in_channels = 8\n",
    "embed_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "\n",
    "class TaskChallenger(nn.Module):\n",
    "    def __init__(self, task_id: int = 1):\n",
    "        super(TaskChallenger, self).__init__()\n",
    "        self.task_id = task_id\n",
    "        self.encoder = LogMelEncoder(num_encoder_blocks=4, num_heads=4)\n",
    "        self.classify_head1 = T1Head()\n",
    "        self.classify_head2 = T2Head()\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x: torch.Tensor = self.encoder(inputs)\n",
    "        if self.task_id == 1:\n",
    "            x = self.classify_head1(x[:, 0, :])  # extract embedding of class token\n",
    "        elif self.task_id == 2:\n",
    "            x = self.classify_head2(x[:, 0, :])  # extract embedding of class token\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "a = torch.randn(batches, in_channels, seq_len, embed_dim)\n",
    "model = TaskChallenger(task_id=2)\n",
    "a = a.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "b: torch.Tensor = model(a)\n",
    "print(f\"a.size(): {a.size()}\")\n",
    "print(f\"b.size(): {b.size()}\")\n",
    "\n",
    "torchinfo.summary(model, inputs_size=a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12 ms ± 413 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b459f3be1e56e33a32566beaaadd8e1cfb2ef221d9a730320e6ef9df4350be20"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('miniconda3-4.7.12': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
